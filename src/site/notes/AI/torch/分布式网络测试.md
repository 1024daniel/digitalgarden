---
{"dg-publish":true,"permalink":"/AI/torch/分布式网络测试/","noteIcon":"3"}
---


#allreduce
```py
import torch
import torch.distributed as dist

def main():
    # Initialize the process group
    dist.init_process_group(backend='gloo', init_method='tcp://<IP_of_Node_1>:<Port>', rank=0, world_size=2)

    # Input tensor on Node 1
    tensor = torch.tensor([1.0, 2.0, 3.0])

    # All-reduce operation
    dist.all_reduce(tensor, op=dist.ReduceOp.SUM)

    # Output the reduced tensor
    print(f"Node 1 - Reduced Tensor: {tensor}")

    # Clean up
    dist.destroy_process_group()

if __name__ == '__main__':
    main()


```